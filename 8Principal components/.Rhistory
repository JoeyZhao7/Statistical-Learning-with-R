[,1] [,2] [,3] [,4] [,5] [,6]
[1,]    0    0    0    0    0    0
[2,]    0    0    0    0    0    0
[3,]    0    0    0    0    0    0
[4,]    0    0    0    0    0    0
[5,]    0    0    0    0    0    0
b=d1[folds==1,]
dim(b)
# [1] 13  7
b
y=d1$hwfat[folds==1]
y
for(j in 1:k)
{
y=d1$hwfat[folds==j]   # y-values in j-th fold
d2 = d1[folds !=j,]    # training set ignores j-th fold
cvmodels = regsubsets(hwfat~.,d2)
for(i in 1:6)
{
newdata = d1[folds==j,]   # test set
yhat = predict.regsubsets(cvmodels,newdata,id=i)
mspe[j,i] = mean((y-yhat)^2)
}
}
mspe
install.packages(leaps)
install.packages("leaps"")
)
""
install.packages("leaps")
install.packages("leaps")
library(leaps)
for(j in 1:k)
{
y=d1$hwfat[folds==j]   # y-values in j-th fold
d2 = d1[folds !=j,]    # training set ignores j-th fold
cvmodels = regsubsets(hwfat~.,d2)
for(i in 1:6)
{
newdata = d1[folds==j,]   # test set
yhat = predict.regsubsets(cvmodels,newdata,id=i)
mspe[j,i] = mean((y-yhat)^2)
}
}
mspe
set.seed(1)
n = nrow(d1)
library(ISLR)
library(pls)
d0= Hitters
dim(d0)
d1 = na.omit(d0)
dim(d1)
head(d1)
set.seed(2)
m1 = pcr(Salary~.,data=d1,scale=T,validation="CV")
summary(m1)
validationplot(m1,main="",)
grid()
set.seed(1)
n = nrow(d1)
n
train = sample(1:n,n/2)
test = [-train]
test = (-train)
dtrain = d1[train]
dtrain = d1[,train]
dtrain = d1[train,]
dtest = d1[test,]
y = d1$Salary
y.test = y[test]
m2 = pcr(Salart~.,data=dtrain,scale=T,validation="CV")
m2 = pcr(Salary~.,data=dtrain,scale=T,validation="CV")
validationplot(m2)
newval = dtest[-,-19]
newval = dtest[,-19]
pred1 = predict(m2,newval,ncomp = 7)
cvk0 = mean((pred1-y.test)^2)
cvk0
head(dtest)
head(dtest)[.19]
head(dtest),.19]
head(dtest)[,19:20]
head(pred1)
plot(pred1~y.test)
plot(pred1~y.test,pch=19/cex=0.6,ylim=c(0,2500))
)
plot(pred1~y.test,pch=19/cex=0.6,ylim=c(0,2500)))
plot(pred1~y.test,pch=19,cex=0.6,ylim=c(0,2500))
abline(0,1)
grid()
m3 = pcr(Salary~.,data=d1,scale=T,ncomp=7)
pred1full = predict(m3,newval,ncomp=7)
cvk0full = mean((pred1full-y)^2)
length(pred1full)
length(y.test)
newval = d1[,19]
pred1full = predict(m3,newval,ncomp=7)
cvk0full = mean((pred1full-y)^2)
newval = d1[,19]
pred1full = predict(m3,newval,ncomp=7)
cvk0full = mean((pred1full-y)^2)
newval = d1[,-19]
pred1full = predict(m3,newval,ncomp=7)
cvk0full = mean((pred1full-y)^2)
cvk0full
predict.regsubsets <- function(object, newdata, id, ...)
{
form <- as.formula(object$call[[2]])
mat <- model.matrix(form, newdata)
coefi = coef(object, id = id)
xvars <- names(coefi)
mat[, xvars]%*%coefi
}
library(leaps)
n = nrows(d1)
n = nrow(d1)
k=10
set.seed(1)
folds = sample(1:k.size=n,replace=T
folds = sample(1:k.size=n,replace=T)
folds = sample(1:k,size=n,replace=T)
table(folds)
mspe = matrix(0,k,19)
dim(mspe)
for(j in 1:k)   # loop folds
{
y = d1$Salary[folds == j]     # y-values in test set
d2 = d1[folds != j,]          # training set
best.fit <- regsubsets(Salary ~.,d2,nvmax=19)
for(i in 1:19)                # i number of predictors in model
{
newdata = d1[folds ==j,]   # test set
yhat <- predict.regsubsets(best.fit,newdata,id=i)
mspe[j, i] <- mean((y - yhat)^2)
}
}
mspe
mspe[,1:7]
cvk = apply(mspe,2,mean)
cvk
plot(cvk,type="l",xlab = "n. of predictors")
which.min(cvk)
sqrt((cvk[11]))
m3 = regsubsets(Salary~.,d1,nvmax=19)
coef(m3,aux=11)
coef(m3,aux)
aux=which.min(cvk)
aux)
coef(m3,aux)
rm(list=ls())
d0=read.table("P1-4.txt")
getwd()
setwd("G:/USC/ISE 529/LECTURE/lecture10-Principal components")
d0=read.table("P1-4.txt")
names(d0)=c("sales","profit","assets")
d1=d0[,c(1,2)]
pr1=prcomp(d1,center=F,scale=F)
names(pr1)
rm(list=ls())
n = 250
mx = 70
sdx = 3
my = 162
sdy = 14
rho = -0.80
mu = c(mx,my)
mu
cova = rho*sdx*sdy
cova
aux = c(sdx^2,cova,cova,sdy^2)
sigma = matrix(aux,nrow=2)
sigma
library(MASS)
d0 = mvrnorm(n,mu,sigma)
d0 = data.frame(d0)
x = d0[,1]
y = d0[,2]
plot(y~x,pch=19,cex=0.6)
m1 = lm(y~x)
abline(m1)
grid()
# same scaling
plot(y~x,pch=19,cex=0.6,xlim=c(10,130),ylim=c(110,210))
abline(m1)
grid()
# principal components
pc1 = prcomp(d0)
rot = pc1$rotation
rot
# 1st PC axis, largest variance
slope1 = rot[2,1]/rot[1,1]
int1 = my - mx*slope1
abline(int1,slope1,col="red",lty=2)
# 2nd PC axis, smallest variance
slope2 = rot[2,2]/rot[1,2]
int2 = my - mx*slope2
abline(int2,slope2,col="blue",lty=2)
legend("topright",c("PC1","PC2","LSq"),col=c("red","blue",1),lty=c(1,1,1))
# enclose 95% of obs in an ellipse
library(mixtools)
ellipse(mu,sigma,0.05,2000,col="red")
rm(list=ls())
# pca.r    James p401
d1=USArrests
dim(d1)             # [1] 50  4
head(d1)
# a) Compare eigenvalues & variances
#=============================================================
summary(d1)
#      Murder          Assault         UrbanPop          Rape
#  Min.   : 0.800   Min.   : 45.0   Min.   :32.00   Min.   : 7.30
#  1st Qu.: 4.075   1st Qu.:109.0   1st Qu.:54.50   1st Qu.:15.07
#  Median : 7.250   Median :159.0   Median :66.00   Median :20.10
#  Mean   : 7.788   Mean   :170.8   Mean   :65.54   Mean   :21.23
#  3rd Qu.:11.250   3rd Qu.:249.0   3rd Qu.:77.75   3rd Qu.:26.18
#  Max.   :17.400   Max.   :337.0   Max.   :91.00   Max.   :46.00
# covariance matrix
var(d1)
#              Murder   Assault   UrbanPop      Rape
# Murder    18.970465  291.0624   4.386204  22.99141
# Assault  291.062367 6945.1657 312.275102 519.26906
# UrbanPop   4.386204  312.2751 209.518776  55.76808
# Rape      22.991412  519.2691  55.768082  87.72916
apply(d1,2,var)
#     Murder    Assault   UrbanPop       Rape
#   18.97047 6945.16571  209.51878   87.72916
apply(d1,2,sd)
#    Murder   Assault  UrbanPop      Rape
#  4.355510 83.337661 14.474763  9.366385
eigen(var(d1))
# $values
# [1] 7011.114851  201.992366   42.112651    6.164246
# $vectors
#             [,1]        [,2]        [,3]        [,4]
# [1,] -0.04170432  0.04482166  0.07989066  0.99492173
# [2,] -0.99522128  0.05876003 -0.06756974 -0.03893830
# [3,] -0.04633575 -0.97685748 -0.20054629  0.05816914
# [4,] -0.07515550 -0.20071807  0.97408059 -0.07232502
sum(eigen(var(d1))$values)  #[1] 7261.384
sum(diag(var(d1)))          #[1] 7261.384
# sum of eigenvalues = sum variances
# means and variances very differents, need to standardize
# b) Find principal components (scaled data)
#=============================================================
m1=prcomp(d1, scale=T)
names(m1)
# [1] "sdev"     "rotation" "center"   "scale"    "x"
# mean and sd of d1 (by default prcomp assumes center=T)
m1$center
#  Murder  Assault UrbanPop     Rape
#   7.788  170.760   65.540   21.232
m1$scale
#   Murder   Assault  UrbanPop      Rape
# 4.355510 83.337661 14.474763  9.366385
# PC loading (eigen) vectors in the rotation matrix
m1$rotation
m1$sdev
# 1.5748783 0.9948694 0.5971291 0.4164494
# score vectors
d2 = m1$x
apply(d2,2,sd)
#       PC1       PC2       PC3       PC4
# 1.5748783 0.9948694 0.5971291 0.4164494
# eigen() function
#=============================================================
cova=var(scale(d1))
#              Murder   Assault   UrbanPop      Rape
# Murder   1.00000000 0.8018733 0.06957262 0.5635788
# Assault  0.80187331 1.0000000 0.25887170 0.6652412
# UrbanPop 0.06957262 0.2588717 1.00000000 0.4113412
# Rape     0.56357883 0.6652412 0.41134124 1.0000000
m2 = eigen(cova)
#$values
#[1] 2.4802416 0.9897652 0.3565632 0.1734301
#$vectors
#          [,1]       [,2]       [,3]        [,4]
#[1,] 0.5358995  0.4181809 -0.3412327  0.64922780
#[2,] 0.5831836  0.1879856 -0.2681484 -0.74340748
#[3,] 0.2781909 -0.8728062 -0.3780158  0.13387773
#[4,] 0.5434321 -0.1673186  0.8177779  0.08902432
# covariance matrix of transformed data
var(d2)
#               PC1           PC2           PC3           PC4
# PC1  2.480242e+00  6.706371e-17  4.573978e-17 -3.198568e-16
# PC2  6.706371e-17  9.897652e-01 -9.581526e-17 -1.516830e-16
# PC3  4.573978e-17 -9.581526e-17  3.565632e-01  5.281033e-17
# PC4 -3.198568e-16 -1.516830e-16  5.281033e-17  1.734301e-01
# Big lambda diagonal matrix (eigenvalues in diagonal)
# eigenvalues in main diagonal
sum(diag(var(d2)))      # 4
# covariances (off diagonal) all equal to 0  (PCs uncorrelated)
# PC1 with largest variance across states
# Use eigenvectors to define the PC variables.
#=====================================================================
m1$rotation
d2 = m1$x
head(d2)
#                  PC1        PC2         PC3          PC4
# Alabama    -0.9756604  1.1220012 -0.43980366  0.154696581
# Alaska     -1.9305379  1.0624269  2.01950027 -0.434175454
# Arizona    -1.7454429 -0.7384595  0.05423025 -0.826264240
# Arkansas    0.1399989  1.1085423  0.11342217 -0.180973554
# California -2.4986128 -1.5274267  0.59254100 -0.338559240
# Colorado   -1.4993407 -0.9776297  1.08400162  0.001450164
tail(m1$x)
#                     PC1        PC2         PC3        PC4
# Vermont       2.7732561  1.3881944  0.83280797 -0.1434337
# Virginia      0.0953667  0.1977278  0.01159482  0.2092464
# Washington    0.2147234 -0.9603739  0.61859067 -0.2186282
# West Virginia 2.0873931  1.4105263  0.10372163  0.1305831
# Wisconsin     2.0588120 -0.6051251 -0.13746933  0.1822534
# Wyoming       0.6231006  0.3177866 -0.23824049 -0.1649769
# Variance of the PCs are the eigenvalues
#================================================================
apply(d2,2,var)
#       PC1       PC2       PC3       PC4
# 2.4802416 0.9897652 0.3565632 0.1734301
# proportion of variance explained (PVE) by each PC
#============================================================
# variance of PCs
aux=m1$sdev^2
#  2.4802416 0.9897652 0.3565632 0.1734301
sum(aux)   # 4
pve=aux/sum(aux)
# [1] 0.62006039 0.24744129 0.08914080 0.04335752
m2$values/4
# [1] 0.62006039 0.24744129 0.08914080 0.04335752
# each eigenvalue divided by 4
cumsum(pve)
# plots
plot(pve, xlab="PC", ylab="% of Variance Explained", ylim=c(0,1),type='l')
grid()
plot(cumsum(pve), xlab="PC", ylab="Cumulative % of Variance Explained", ylim=c(0,1),type='l')
grid()
# biplots
#============================================================
biplot(m1, scale=0)
biplot(m1, scale=0,cex=0.6)
grid()
# mirror image
m1$rotation=-m1$rotation
m1$x=-m1$x
biplot(m1, scale=0,cex=0.6)
grid()
# axis found in 1st two cols of rotation matrix
rot=m1$rotation
#                PC1        PC2        PC3         PC4
# Murder   0.5358995 -0.4181809  0.3412327 -0.64922780
# Assault  0.5831836 -0.1879856  0.2681484  0.74340748
# UrbanPop 0.2781909  0.8728062  0.3780158 -0.13387773
# Rape     0.5434321  0.1673186 -0.8177779 -0.08902432
# Murder axis
slope1=rot[1,2]/rot[1,1]
slope1   # -0.7803345
abline(0,slope1)
rm(list=ls())
# pcr2.r    James p256
library(pls)    # pcr()
library(ISLR)   # Hitters data
d0=Hitters        # 19 predictors, one response
dim(d0)           #[1] 322  20
d1 = na.omit(d0)  # removes NAs across all cols
dim(d1)           #[1] 263  20
# a) model with standardized predictors (full dataset)
#============================================================
set.seed(2)
m1=pcr(Salary~.,data=d1,scale=T,validation="CV")  # word data required
summary(m1)
# Data:   X dimension: 263 19
#         Y dimension: 263 1
# Fit method: svdpc                         # singular value decomposition
# Number of components considered: 19
# VALIDATION: RMSEP
# Cross-validated using 10 random segments.
#        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps
# CV             452    348.9    352.2    353.5    352.8    350.1    349.1
# adjCV          452    348.7    351.8    352.9    352.1    349.3    348.0
#        7 comps  8 comps  9 comps  10 comps  11 comps  12 comps  13 comps
# CV       349.6    350.9    352.9     353.8     355.0     356.2     363.5
# adjCV    348.5    349.8    351.6     352.3     353.4     354.5     361.6
#        14 comps  15 comps  16 comps  17 comps  18 comps  19 comps
# CV        355.2     357.4     347.6     350.1     349.2     352.6
# adjCV     352.8     355.2     345.5     347.6     346.7     349.8
# TRAINING: % variance explained
#         1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps
# X         38.31    60.16    70.84    79.03    84.29    88.63    92.26
# Salary    40.63    41.58    42.17    43.22    44.90    46.48    46.69
#         8 comps  9 comps  10 comps  11 comps  12 comps  13 comps
# X         94.96    96.28     97.26     97.98     98.65     99.15
# Salary    46.75    46.86     47.76     47.82     47.85     48.10
#         14 comps  15 comps  16 comps  17 comps  18 comps  19 comps
# X          99.47     99.75     99.89     99.97     99.99    100.00
# Salary     50.40     50.55     53.01     53.85     54.61     54.61
# validation = CV, computes 10-fold CV errors for M components in the model
# RMSEP = sqrt(MSPE)
# % variance explained shows or predictors and Salary explained by model
# b) plot the 10-fold cv errors vs number of PCs
#==========================================================
validationplot(m1,main=""); grid()
validationplot(m1,val.type="MSEP",main="",legend="top"); grid()
validationplot(m1,val.type = "R2",main=""); grid()
# c) PCR with training set
#=====================================================================
set.seed(1)
n=nrow(d1)
train=sample(1:n,n/2)    # 50/50
test=(-train)
dtrain=d1[train,]
dtest=d1[test,]
y=d1$Salary
y.test=y[test]
m2=pcr(Salary~.,data=dtrain,scale=T, validation="CV")   # word data required
# training plot
validationplot(m2,val.type="MSEP",main="",legendpos="top"); grid()
# lowest CV error when M=7 principal components
# test MSE
newval = dtest[,-19]                       # needed?
pred1=predict(m2,newval,ncomp=7)
cvk0 = mean((pred1-y.test)^2)               #[1] 96556.22
# compare predictions vs Salary
head(dtest)[,19:20]
#                 Salary NewLeague
#-Alan Ashby         475         N
#-Andre Dawson       500         N
#-Alfredo Griffin    750         A
#-Argenis Salazar    100         A
#-Andres Thomas       75         N
#-Andre Thornton    1100         A
head(y.test)   # [1]  475  500  750  100   75 1100
head(pred1)    # [1] 613.61332 906.59077 509.76018  28.21284 108.83181 831.63034
plot(pred1~y.test)
plot(pred1~y.test,pch=19,cex=0.6,ylim=c(0,2500))
abline(0,1)
grid()
# predicting a single obs
newval = dtrain[,-19]
newval[1,] = data.frame(AtBat=315 ,Hits= 99, HmRun=22 , Runs=33 , RBI=44 , Walks=33 , Years=11 , CAtBat=3000 , CHits=999 , CHmRun=77 , CRuns=344 , CRBI=233 , CWalks=333 , League="N" , Division="W" , PutOuts=444 , Assists=55 , Errors=11 ,NewLeague= "A")
newval = newval[1,]
pred1=predict(m2,newval,ncomp=7)
#                     Salary
#-Darryl Strawberry 484.6758
# fit PCR on full data set using M=7
#===============================================================
m3=pcr(Salary~.,data=d1,scale=T,ncomp=7)
summary(m3)
#Data:   X dimension: 263 19
#        Y dimension: 263 1
#Fit method: svdpc
#Number of components considered: 7
#TRAINING: % variance explained
#   1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps
#X    38.31    60.16    70.84    79.03    84.29    88.63    92.26
#y    40.63    41.58    42.17    43.22    44.90    46.48    46.69
# test MSE
newval = d1[,-19]
pred1full=predict(m3,newval,ncomp=7)
cvk0full = mean((pred1full-y)^2)               #[1] 108084.9
# plot prediction performance of model with 7 PCs
#plot(pred1full~y)
plot(pred1full~y,pch=19,cex=0.6,ylim=c(0,2500))
abline(0,1)
grid()
# 10-fold CV on MLR
# ====================================================
# load predict.regsubsets() function
library(leaps)        # regsubsets()
n <- nrow(d1)         # [1] 263
k <- 10               # set the number of folds equal to 5
set.seed(1)           # set for reproducible results
# test sets
folds <- sample(1:k,size = n,replace=T)
# vector with nums 1 to 10 (which rows belong to each of 10 folds)
folds[1:22]
# 3  4  6 10  3  9 10  7  7  1  3  2  7  4  8  5  8 10  4  8 10  3
table(folds)
#  1  2  3  4  5  6  7  8  9 10
# 13 25 31 32 33 27 26 30 22 24    # sizes of test sets, not same in all folds
mspe <- matrix(0, k, 19)           # matrix of 0s
dim(mspe)    # [1] 10 19
# mspe[j,i] = MSPE of best model with i predictors using jth fold
for(j in 1:k)   # loop folds
{
y = d1$Salary[folds == j]     # y-values in test set
d2 = d1[folds != j,]          # training set
best.fit <- regsubsets(Salary ~.,d2,nvmax=19)
for(i in 1:19)                # i number of predictors in model
{
newdata = d1[folds ==j,]   # test set
yhat <- predict.regsubsets(best.fit,newdata,id=i)
mspe[j, i] <- mean((y - yhat)^2)
}
}
mspe[,1:7]
#           [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
# [1,] 187479.08 141652.61 163000.36 169584.40 141745.39 151086.36 193584.17
# [2,]  96953.41  63783.33  85037.65  76643.17  64943.58  56414.96  63233.49
# [3,] 165455.17 167628.28 166950.43 152446.17 156473.24 135551.12 137609.30
# [4,] 124448.91 110672.67 107993.98 113989.64 108523.54  92925.54 104522.24
# [5,] 136168.29  79595.09  86881.88  94404.06  89153.27  83111.09  86412.18
# [6,] 171886.20 120892.96 120879.58 106957.31 100767.73  89494.38  94093.52
# [7,]  56375.90  74835.19  72726.96  59493.96  64024.85  59914.20  62942.94
# [8,]  93744.51  85579.47  98227.05 109847.35 100709.25  88934.97  90779.58
# [9,] 421669.62 454728.90 437024.28 419721.20 427986.39 401473.33 396247.58
#[10,] 146753.76 102599.22 192447.51 208506.12 214085.78 224120.38 214037.26
# rows are folds
# mspe on i fold when using best model with j predictors
cvk <- apply(mspe, 2, mean)
# [1] 160093.5 140196.8 153117.0 151159.3 146841.3 138302.6 144346.2 130207.7 129459.6 125334.7 125153.8 128273.5 133461.0 133974.6 131825.7 131882.8
#[17] 132750.9 133096.2 132804.7
plot(cvk,type="l",xlab="n. of predictors")
grid()
